{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IH_TlH3wc3a3"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import helper\n",
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n",
        "from keras.layers import Embedding\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras.models import Sequential\n",
        "import pickle\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, Conv1D, MaxPool1D, Dense, Flatten, Dropout, AveragePooling2D, LSTM, TimeDistributed, Attention\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import models, layers\n",
        "from keras import backend\n",
        "from sklearn.metrics import f1_score,recall_score,precision_score, confusion_matrix\n",
        "from keras_self_attention import SeqSelfAttention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZMX6Xm7Bdek",
        "outputId": "174448ff-bfc6-4504-c008-48f1071bf043"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-self-attention\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-self-attention) (1.21.6)\n",
            "Building wheels for collected packages: keras-self-attention\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18912 sha256=617dbecb8e10bc79d3a20de82e3db43205f60ff3c901bc0ade797033f0758de3\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/b1/a8/5ee00cc137940b2f6fa198212e8f45d813d0e0d9c3a04035a3\n",
            "Successfully built keras-self-attention\n",
            "Installing collected packages: keras-self-attention\n",
            "Successfully installed keras-self-attention-0.51.0\n"
          ]
        }
      ],
      "source": [
        "pip install keras-self-attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "B1eduBjkBRJw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARq3Hlw6c3a7",
        "outputId": "1b853d91-76e5-4d3a-f1d3-4723ffe8de09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/SLU Semesters/SLU 3rd Semester/NLP/Fifth Competition\n",
            "Anything-v3.ipynb  Neural_Machine_Translation.ipynb  \u001b[0m\u001b[01;34mtrain-05\u001b[0m/\n",
            "\u001b[01;34mmodels\u001b[0m/            \u001b[01;34mtest-05\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/SLU Semesters/SLU 3rd Semester/NLP/Fifth Competition/\n",
        "\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xVjkxNcKc3a8"
      },
      "outputs": [],
      "source": [
        "# def read_data(file_name):\n",
        "#   data=[]\n",
        "#   with open(file_name, encoding='utf8') as f:\n",
        "#     for line in f:\n",
        "#       line=line.strip()\n",
        "#       data.append(line)\n",
        "#   size = len(data)\n",
        "#   idx_list = [idx + 1 for idx, val in\n",
        "#             enumerate(data) if val == '</s>']\n",
        "#   res = [data[i: j] for i, j in\n",
        "#         zip([0] + idx_list, idx_list + \n",
        "#         ([size] if idx_list[-1] != size else []))]\n",
        "#   return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G37itZVo-zRi"
      },
      "outputs": [],
      "source": [
        "# def read_data(file_name):\n",
        "#     all_data = []\n",
        "#     descript = 'Reading ' + file_name\n",
        "\n",
        "#     f = open(file_name, 'r', encoding='utf-8')\n",
        "#     full_text = f.read()\n",
        "\n",
        "#     cur_sent = []\n",
        "\n",
        "#     for line in tqdm(full_text.split('\\n'), desc=descript):\n",
        "#         if line == '<s>':\n",
        "#             cur_sent = []\n",
        "#             continue\n",
        "#         if line in '()':\n",
        "#             continue\n",
        "#         if line == '</s>':\n",
        "#             all_data.append(cur_sent)\n",
        "#             continue\n",
        "#         else:\n",
        "#             cur_sent.append(line.lower())\n",
        "\n",
        "#     return all_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xxjx_t4yfV0y"
      },
      "outputs": [],
      "source": [
        "def read_data(file_name):\n",
        "    output = []\n",
        "    cur_sent = []\n",
        "    source_file = open(file_name, 'r', encoding='utf-8')\n",
        "    text = source_file.read()\n",
        "\n",
        "    for current in (text.split('\\n')):\n",
        "        if current == '<s>':\n",
        "            cur_sent = []\n",
        "            continue\n",
        "        if current == '</s>':\n",
        "            output.append(cur_sent)\n",
        "            continue\n",
        "        if current in '()':\n",
        "            continue\n",
        "        else:\n",
        "            cur_sent.append(current.lower())\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9v8T6Dtitl4",
        "outputId": "647ecc4a-6e0b-4e04-d4e1-78850f52eea0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Anything-v3.ipynb  Neural_Machine_Translation.ipynb  \u001b[0m\u001b[01;34mtrain-05\u001b[0m/\n",
            "\u001b[01;34mmodels\u001b[0m/            \u001b[01;34mtest-05\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jA4UyvNtc3a8"
      },
      "outputs": [],
      "source": [
        "# source: https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd\n",
        "def tokenize(x):\n",
        "    x_tk = Tokenizer(char_level = False)\n",
        "    x_tk.fit_on_texts(x)\n",
        "    return x_tk.texts_to_sequences(x), x_tk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "di7wYtWac3a9"
      },
      "outputs": [],
      "source": [
        "# source: https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd\n",
        "def pad(x, length=None):\n",
        "    if length is None:\n",
        "        length = max([len(sentence) for sentence in x])\n",
        "    return pad_sequences(x, maxlen = length, padding = 'post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gxVc8XYoc3a9"
      },
      "outputs": [],
      "source": [
        "# source: https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd\n",
        "def preprocess(x, y):\n",
        "    preprocess_x, x_tk = tokenize(x)\n",
        "    preprocess_y, y_tk = tokenize(y)\n",
        "\n",
        "    preprocess_x = pad(preprocess_x)\n",
        "    preprocess_y = pad(preprocess_y)\n",
        "\n",
        "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
        "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
        "\n",
        "    return preprocess_x, preprocess_y, x_tk, y_tk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Js_uhC6dU4uz"
      },
      "outputs": [],
      "source": [
        "# source: https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd\n",
        "def logits_to_text(logits, tokenizer):\n",
        "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "    index_to_words[0] = ''\n",
        "\n",
        "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6XO6qxbyVCsh"
      },
      "outputs": [],
      "source": [
        "# source: https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd\n",
        "\n",
        "def bd_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    learning_rate = 1e-3\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(GRU(128, return_sequences = True, dropout = 0.1), \n",
        "                           input_shape = input_shape[1:]))\n",
        "    model.add(TimeDistributed(Dense(french_vocab_size, activation = 'softmax')))\n",
        "    model.compile(loss = sparse_categorical_crossentropy, \n",
        "                 optimizer = Adam(learning_rate), \n",
        "                 metrics = ['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew5gjNRvUv9O",
        "outputId": "a771ec2a-656a-42f9-cec3-740b1003db8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "source_train = read_data('train-05/train-source.txt')\n",
        "target_train = read_data('train-05/train-target.txt')\n",
        "\n",
        "source = read_data('test-05/test-source.txt')\n",
        "target = read_data('test-05/test-target.txt')\n",
        "\n",
        "len(source)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr69J4FQXZXV",
        "outputId": "69b46128-6f1d-4c5f-a369-c84875a553e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Preprocessed\n",
            "Max source sentence length: 231\n",
            "Max target sentence length: 221\n",
            "Source vocabulary size: 31035\n",
            "Target vocabulary size: 25735\n"
          ]
        }
      ],
      "source": [
        "# source: https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd\n",
        "\n",
        "preproc_source_train, preproc_target_train, source_train_tokenizer, target_train_tokenizer =\\\n",
        "    preprocess(source_train, target_train)\n",
        "    \n",
        "max_source_train_length = preproc_source_train.shape[1]\n",
        "max_target_train_length = preproc_target_train.shape[1]\n",
        "source_train_vocab_size = len(source_train_tokenizer.word_index)\n",
        "target_train_vocab_size = len(target_train_tokenizer.word_index)\n",
        "\n",
        "max_train_target_length = preproc_target_train.shape[1]\n",
        "\n",
        "print('Data Preprocessed')\n",
        "print(\"Max source sentence length:\", max_source_train_length)\n",
        "print(\"Max target sentence length:\", max_target_train_length)\n",
        "print(\"Source vocabulary size:\", source_train_vocab_size)\n",
        "print(\"Target vocabulary size:\", target_train_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zeho1L-kkVBc",
        "outputId": "08f2896b-67d4-4ca8-9acc-732c8764965d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Preprocessed\n",
            "Max source sentence length: 97\n",
            "Max target sentence length: 92\n",
            "Source vocabulary size: 3215\n",
            "Target vocabulary size: 2997\n"
          ]
        }
      ],
      "source": [
        "# source: https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd\n",
        "\n",
        "preproc_source, preproc_target, source_tokenizer, target_tokenizer =\\\n",
        "    preprocess(source, target)\n",
        "    \n",
        "max_source_length = preproc_source.shape[1]\n",
        "max_target_length = preproc_target.shape[1]\n",
        "source_vocab_size = len(source_tokenizer.word_index)\n",
        "target_vocab_size = len(target_tokenizer.word_index)\n",
        "\n",
        "max_train_target_length = preproc_target.shape[1]\n",
        "\n",
        "print('Data Preprocessed')\n",
        "print(\"Max source sentence length:\", max_source_length)\n",
        "print(\"Max target sentence length:\", max_target_length)\n",
        "print(\"Source vocabulary size:\", source_vocab_size)\n",
        "print(\"Target vocabulary size:\", target_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snJi20iBYKhY",
        "outputId": "62b5edea-5621-49e2-c32f-421d36af4f03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "92"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_target_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "LVBzJguC2IEu"
      },
      "outputs": [],
      "source": [
        "#########\n",
        "tmp_x = pad(preproc_source, max_target_train_length)\n",
        "tmp_x = tmp_x.reshape((-1, preproc_target_train.shape[-2], 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "49xi-SWCc3bB"
      },
      "outputs": [],
      "source": [
        "# # source: https://towardsdatascience.com/neural-machine-translation-with-python-c2f0a34f7dd\n",
        "# # Train bi-directional\n",
        "# tmp_x = pad(preproc_source, preproc_target.shape[1])\n",
        "# tmp_x = tmp_x.reshape((-1, preproc_target.shape[-2], 1))\n",
        "\n",
        "# bidi_model = bd_model(\n",
        "#     tmp_x.shape,\n",
        "#     preproc_target.shape[1],\n",
        "#     len(source_tokenizer.word_index)+1,\n",
        "#     len(target_tokenizer.word_index)+1)\n",
        "\n",
        "\n",
        "# bidi_model.fit(tmp_x, preproc_target, batch_size=32, epochs=1, validation_split=0.2)\n",
        "\n",
        "# # Print prediction(s)\n",
        "# print(logits_to_text(bidi_model.predict(tmp_x[:1])[0], target_tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acBrCgzOnE-E"
      },
      "outputs": [],
      "source": [
        "# bidi_model.save('./models/bidire_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7P9Rkg0TSuV-"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "loaded_bid = load_model(\"./models/bidire_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbgIYB40TVC9",
        "outputId": "7e9130b4-844b-4ec2-93b5-4dfeb1e273a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 7s 7s/step\n"
          ]
        }
      ],
      "source": [
        "predictions = loaded_bid.predict(tmp_x[:1])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "5Du-lKwfbVjS",
        "outputId": "4ade139c-add3-4d38-a8ab-9653471115aa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bhí an an . an . . . . . . . . . . . . . a a                                                                                                                                                                                                         '"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "real = (tmp_x[:1])[0]\n",
        "real = logits_to_text(predictions, source_tokenizer)\n",
        "real"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "hHSCNd_KZzlA",
        "outputId": "0f1b0e24-afbf-4547-a8cb-f6616cd68cf7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bhí an an . an . . . . . . . . . . . . . a a                                                                                                                                                                                                         '"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_words = logits_to_text(predictions, target_tokenizer)\n",
        "(final_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22hfvIw4aQ1n"
      },
      "outputs": [],
      "source": [
        "source[0]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
