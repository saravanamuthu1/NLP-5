{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMS9fKTUbKXbxqDNK0zWxcf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saravanamuthu1/NLP-5/blob/main/Untitled22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "N3vNw7tJQ7yo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "import keras\n",
        "from keras.layers import LSTM, Dense, GRU, Embedding\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from math import log2\n",
        "from keras.layers import Embedding, LSTM, Dense,Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "import keras.utils as ku \n",
        "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "import string\n",
        "import re\n",
        "from unicodedata import normalize\n",
        "from pickle import load\n",
        "from numpy import array, argmax\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import load_model\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(file_name):\n",
        "  data=[]\n",
        "  with open(file_name, encoding='utf8') as f:\n",
        "    for line in f:\n",
        "      line=line.strip()\n",
        "      data.append(line)\n",
        "  unique_words= list(set(data))\n",
        "  size = len(data)\n",
        "  idx_list = [idx + 1 for idx, val in\n",
        "            enumerate(data) if val == '</s>']\n",
        "  res = [data[i: j] for i, j in\n",
        "        zip([0] + idx_list, idx_list + \n",
        "        ([size] if idx_list[-1] != size else []))]\n",
        "  return res,unique_words\n"
      ],
      "metadata": {
        "id": "eOPHRxR_h86T"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_data,unique_source_words=read_data(\"train-source.txt\")"
      ],
      "metadata": {
        "id": "HOPtpzkfigAS"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_data,unique_target_data_words=read_data(\"train-target.txt\")"
      ],
      "metadata": {
        "id": "1MXzY2TsijDq"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_pairs(lines):\n",
        "    cleaned = list()\n",
        "    for pair in lines:\n",
        "        clean_pair = list()\n",
        "        for line in pair:\n",
        "            if line == \"<s>\" and line == \"</s>\":\n",
        "              continue\n",
        "            else:\n",
        "              line = line.lower()\n",
        "              clean_pair.append(''.join(line))\n",
        "        cleaned.append(clean_pair)\n",
        "    return cleaned\n"
      ],
      "metadata": {
        "id": "EYp98eQSjcps"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_source=clean_pairs(source_data)\n",
        "clean_target=clean_pairs(target_data)"
      ],
      "metadata": {
        "id": "vaeB5QXIk7j4"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections"
      ],
      "metadata": {
        "id": "ssL-nywKyinu"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_counter = collections.Counter([word for sentence in clean_source for word in sentence])\n",
        "target_counter = collections.Counter([word for sentence in clean_target for word in sentence])\n",
        "\n",
        "print('{} Source words.'.format(len([word for sentence in clean_source for word in sentence])))\n",
        "print('{} unique source words.'.format(len(source_counter)))\n",
        "print('10 Most common words in the source dataset:')\n",
        "print('\"' + '\" \"'.join(list(zip(*source_counter.most_common(10)))[0]) + '\"')\n",
        "print()\n",
        "print('{} Target words.'.format(len([word for sentence in clean_target for word in sentence])))\n",
        "print('{} unique target words.'.format(len(target_counter)))\n",
        "print('10 Most common words in the target dataset:')\n",
        "print('\"' + '\" \"'.join(list(zip(*target_counter.most_common(10)))[0]) + '\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gEWiCBnx8zY",
        "outputId": "00a77041-dfde-493e-f814-ab6cfa131c70"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "925534 Source words.\n",
            "31039 unique source words.\n",
            "10 Most common words in the source dataset:\n",
            "\"<s>\" \"</s>\" \".\" \"a\" \"an\" \",\" \"agus\" \"ar\" \"\"\" \"bhí\"\n",
            "\n",
            "910804 Target words.\n",
            "25739 unique target words.\n",
            "10 Most common words in the target dataset:\n",
            "\"<s>\" \"</s>\" \".\" \"a\" \"an\" \",\" \"agus\" \"ar\" \"bhí\" \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(x):\n",
        "    \"\"\"\n",
        "    Tokenize x\n",
        "    :param x: List of sentences/strings to be tokenized\n",
        "    :return: Tuple of (tokenized x data, tokenizer used to tokenize x)\n",
        "    \"\"\"\n",
        "    # TODO: Implement\n",
        "    tokenizer = Tokenizer(split=' ', char_level=False)\n",
        "    tokenizer.fit_on_texts(x)\n",
        "    return tokenizer.texts_to_sequences(x), tokenizer           # texts_to_sequences_generator(), Yields individual sequences.\n"
      ],
      "metadata": {
        "id": "Kqiy78xcydPY"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad(x, length=None):\n",
        "    \"\"\"\n",
        "    Pad x\n",
        "    :param x: List of sequences.\n",
        "    :param length: Length to pad the sequence to.  If None, use length of longest sequence in x.\n",
        "    :return: Padded numpy array of sequences\n",
        "    \"\"\"\n",
        "    # TODO: Implement\n",
        "    if length is None:\n",
        "        length = max([len(sentence) for sentence in x])\n",
        "    \n",
        "    return pad_sequences(x, maxlen=length, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "BF6NabVNyvHV"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(x, y):\n",
        "    \"\"\"\n",
        "    Preprocess x and y\n",
        "    :param x: Feature List of sentences\n",
        "    :param y: Label List of sentences\n",
        "    :return: Tuple of (Preprocessed x, Preprocessed y, x tokenizer, y tokenizer)\n",
        "    \"\"\"\n",
        "    preprocess_x, x_tk = tokenize(x)\n",
        "    preprocess_y, y_tk = tokenize(y)\n",
        "\n",
        "    preprocess_x = pad(preprocess_x)\n",
        "    preprocess_y = pad(preprocess_y)\n",
        "\n",
        "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
        "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
        "\n",
        "    return preprocess_x, preprocess_y, x_tk, y_tk\n",
        "\n",
        "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer =\\\n",
        "    preprocess(clean_source,clean_target)\n",
        "    \n",
        "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
        "max_french_sequence_length = preproc_french_sentences.shape[1]\n",
        "english_vocab_size = len(english_tokenizer.word_index)\n",
        "french_vocab_size = len(french_tokenizer.word_index)\n",
        "\n",
        "print('Data Preprocessed')\n",
        "print(\"Max English sentence length:\", max_english_sequence_length)\n",
        "print(\"Max French sentence length:\", max_french_sequence_length)\n",
        "print(\"English vocabulary size:\", english_vocab_size)\n",
        "print(\"French vocabulary size:\", french_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DSOPHzqyw71",
        "outputId": "b040482d-9653-4c81-c7ae-db3b58973ff4"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Preprocessed\n",
            "Max English sentence length: 233\n",
            "Max French sentence length: 223\n",
            "English vocabulary size: 31039\n",
            "French vocabulary size: 25739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def token_to_words(sequence, tokenizer):\n",
        "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "    index_to_words[0] = ''\n",
        "\n",
        "    return [index_to_words[token] for token in sequence if index_to_words[token]!='']"
      ],
      "metadata": {
        "id": "7UOUQFJNzsGI"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_final(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    \"\"\"\n",
        "    Build and train a model that incorporates embedding, encoder-decoder, and bidirectional RNN on x and y\n",
        "    :param input_shape: Tuple of input shape\n",
        "    :param output_sequence_length: Length of output sequence\n",
        "    :param english_vocab_size: Number of unique English words in the dataset\n",
        "    :param french_vocab_size: Number of unique French words in the dataset\n",
        "    :return: Keras model built, but not trained\n",
        "    \"\"\"\n",
        "    \n",
        "    learning_rate = 6e-3\n",
        "    embedding_size = 256\n",
        "    units = 256\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    ########### ENCODER ###########\n",
        "    \n",
        "    model.add(Embedding(input_dim = english_vocab_size, output_dim = embedding_size, \n",
        "                           input_length= input_shape[1], name=\"Embedding_layer\"))\n",
        "    model.add(Bidirectional(LSTM(units, return_sequences=False), name='Bi_LSTM_encoder'))\n",
        "    \n",
        "    ########### INTERMEDIARY ###########\n",
        "    \n",
        "    model.add(RepeatVector(output_sequence_length, name='Glue'))\n",
        "    \n",
        "    ########### DECODER ###########\n",
        "    \n",
        "    model.add(LSTM(units, return_sequences=True, name='LSTM_decoder'))\n",
        "    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax'), name='Dense'))\n",
        "    \n",
        "    ########### END-TO-END MODEL ###########\n",
        "    \n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n"
      ],
      "metadata": {
        "id": "lu4nwSG5y3gf"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Train the final model\n",
        "\n",
        "tmp_x = pad(preproc_english_sentences, max_french_sequence_length) # pad input sequence to output sequence length\n",
        "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2]))    # reshape for embedding input\n",
        "\n",
        "# Train the neural network\n",
        "final_model = model_final(\n",
        "                        tmp_x.shape,\n",
        "                        max_french_sequence_length,\n",
        "                        english_vocab_size,\n",
        "                        french_vocab_size)\n",
        "\n",
        "final_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc4V2nfnLu6A",
        "outputId": "5eb2fa29-0295-49c8-be84-f8adcd19a07d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Embedding_layer (Embedding)  (None, 223, 256)         7945984   \n",
            "                                                                 \n",
            " Bi_LSTM_encoder (Bidirectio  (None, 512)              1050624   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " Glue (RepeatVector)         (None, 223, 512)          0         \n",
            "                                                                 \n",
            " LSTM_decoder (LSTM)         (None, 223, 256)          787456    \n",
            "                                                                 \n",
            " Dense (TimeDistributed)     (None, 223, 25739)        6614923   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,398,987\n",
            "Trainable params: 16,398,987\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOtkurMHis1k",
        "outputId": "34a394e7-3b34-4f63-9545-e01885d0dc04"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1,  259,   13,  350,    6,  172,  962,  307,    4,  281,    8,\n",
              "       1898,    5, 4805, 2822,    3,    2,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.fit(tmp_x, preproc_french_sentences, batch_size=124, epochs=5, validation_split=0.2)\n",
        "\n",
        "print('Final Model Loaded')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTspxcMZLqNN",
        "outputId": "e5bc6da8-dd6a-4a88-dead-ade6c1a15e98"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "292/292 [==============================] - 352s 1s/step - loss: 1.0538 - accuracy: 0.9059 - val_loss: nan - val_accuracy: 0.9212\n",
            "Epoch 2/5\n",
            "292/292 [==============================] - 346s 1s/step - loss: 0.8172 - accuracy: 0.9123 - val_loss: nan - val_accuracy: 0.9212\n",
            "Epoch 3/5\n",
            "292/292 [==============================] - 347s 1s/step - loss: 0.7899 - accuracy: 0.9123 - val_loss: nan - val_accuracy: 0.9212\n",
            "Epoch 4/5\n",
            "292/292 [==============================] - 347s 1s/step - loss: 0.7871 - accuracy: 0.9123 - val_loss: nan - val_accuracy: 0.9212\n",
            "Epoch 5/5\n",
            "292/292 [==============================] - 347s 1s/step - loss: 0.7870 - accuracy: 0.9125 - val_loss: nan - val_accuracy: 0.9214\n",
            "Final Model Loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def logits_to_text(logits, tokenizer):\n",
        "    \"\"\"\n",
        "    Turn logits from a neural network into text using the tokenizer\n",
        "    :param logits: Logits from a neural network\n",
        "    :param tokenizer: Keras Tokenizer fit on the labels\n",
        "    :return: String that represents the text of the logits\n",
        "    \"\"\"\n",
        "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "    index_to_words[0] = ''\n",
        "\n",
        "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1) if index_to_words[prediction]!=''] )\n",
        "\n",
        "print('`logits_to_text` function loaded.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUiYKYlAZVlp",
        "outputId": "ef6d9c20-6ba2-4045-a346-ffdbf981ba3d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`logits_to_text` function loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(prediction, gold_standard):\n",
        "    \n",
        "    translation = logits_to_text(prediction[0], french_tokenizer)\n",
        "    standard = ' '.join(token_to_words(gold_standard[0][:,0],french_tokenizer)) \n",
        "    print('---- Gold standard ----')\n",
        "    print(standard)\n",
        "    print()\n",
        "    print('---- Prediction ----')\n",
        "    for w_t, w_s in zip(translation.split(), standard.split()):\n",
        "        if w_t == w_s:\n",
        "            print('\\033[0;30;0m','{}'.format(w_t), end='')\n",
        "        else:\n",
        "            print('\\033[0;31;47m', w_t, end='')\n",
        "    print()"
      ],
      "metadata": {
        "id": "tQ6vdJ3QZQui"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('---- Original ----')\n",
        "print(' '.join(token_to_words(tmp_x[:1][0],english_tokenizer) ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJzTRh2WML02",
        "outputId": "2e23d702-2b8a-4eb1-cd0e-39599219bbbc"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- Original ----\n",
            "<s> cinnte go leór , thiocfadh dóbhtha bás a fhagháil ar imeall an phuill udaí . </s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate(final_model.predict(tmp_x[:1]), preproc_french_sentences[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "vs7zBde7hNss",
        "outputId": "91b45c40-db03-4f82-d57b-aadd206dd2d7"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-ed0983af323d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreproc_french_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\ntranspose expects a vector of size 2. But input(1) is a vector of size 3\n\t [[{{node transpose}}]]\n\t [[sequential_3/Bi_LSTM_encoder/forward_lstm_2/PartitionedCall]] [Op:__inference_predict_function_97689]"
          ]
        }
      ]
    }
  ]
}