{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPR9EklINGGKexkBvk2LIpV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saravanamuthu1/NLP-5/blob/working_branch/machine_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "u36zqKBtt5fA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "import keras\n",
        "from keras.layers import LSTM, Dense, GRU, Embedding\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from math import log2\n",
        "from keras.layers import Embedding, LSTM, Dense,Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "import keras.utils as ku "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#readind the data\n"
      ],
      "metadata": {
        "id": "O5pUP30Me3Z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(file_name):\n",
        "  data=[]\n",
        "  with open(file_name, encoding='utf8') as f:\n",
        "    for line in f:\n",
        "      line=line.strip()\n",
        "      data.append(line)\n",
        "  size = len(data)\n",
        "  idx_list = [idx + 1 for idx, val in\n",
        "            enumerate(data) if val == '</s>']\n",
        "  res = [data[i: j] for i, j in\n",
        "        zip([0] + idx_list, idx_list + \n",
        "        ([size] if idx_list[-1] != size else []))]\n",
        "  return res\n"
      ],
      "metadata": {
        "id": "-N1zkY1ouOe0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finding the maximum length of the input sequence\n"
      ],
      "metadata": {
        "id": "PLyizZxme6YW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_max_len(data_set):\n",
        "  list_length=0\n",
        "  li=[]\n",
        "  for i in data_set:\n",
        "    if list_length < len(i):\n",
        "      list_length = len(i)\n",
        "  return list_length\n"
      ],
      "metadata": {
        "id": "N-FXduYmM75q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#read source data\n"
      ],
      "metadata": {
        "id": "XSP9ZfH0fFTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_data=read_data(\"train-source.txt\")"
      ],
      "metadata": {
        "id": "sRIARsLkvaqp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Find the maximum sequence in source data\n"
      ],
      "metadata": {
        "id": "-n6wvgWwfIv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_value_source_data=find_max_len(source_data)"
      ],
      "metadata": {
        "id": "pbjEB_4-Nby1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_value_source_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxzsMoBJNomO",
        "outputId": "447e5df4-1a7f-4322-9da4-430d0ec38e6b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "233"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#read the target data"
      ],
      "metadata": {
        "id": "Zbk4a7q0fQvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_data=read_data(\"train-target.txt\")"
      ],
      "metadata": {
        "id": "NFQctcZbvkEL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#find the maximum sequence in target data\n"
      ],
      "metadata": {
        "id": "rL_hBoDvfYZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_value_target_data=find_max_len(target_data)"
      ],
      "metadata": {
        "id": "7a4BRjIZNh1-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_value_target_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXTPUichNa0U",
        "outputId": "8833a4a5-fbaf-41b2-95bb-4355e56efec0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "223"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Length of the source data and taget data"
      ],
      "metadata": {
        "id": "wryZP_hEfiVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(source_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA_OV_4LKfN-",
        "outputId": "56035c4e-b03d-4ec0-b67a-bd83aac2c88b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45171"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(target_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9uNDAEGMzz-",
        "outputId": "54c4e27c-2907-4fca-98d3-0aa90823e8a3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45171"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#total number of unique words in thedataset"
      ],
      "metadata": {
        "id": "c473edaCfo0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def total_words(data):\n",
        "  all_source_data_words=set()\n",
        "  for sentence in data:\n",
        "    for word in sentence:\n",
        "      if word not in all_source_data_words:\n",
        "        all_source_data_words.add(word)\n",
        "  return all_source_data_words\n"
      ],
      "metadata": {
        "id": "J_Tj5GjEM1oX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_data_words=sorted(list(total_words(source_data)))"
      ],
      "metadata": {
        "id": "mK49s4-sTSNu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_data_words=sorted(list(total_words(target_data)))"
      ],
      "metadata": {
        "id": "0uUysgkPTZg9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#initalise the variables"
      ],
      "metadata": {
        "id": "eCg8Gw-wfuo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "length_encoder_tokens=len(source_data_words)\n",
        "length_decoder_tokens=len(target_data_words)"
      ],
      "metadata": {
        "id": "GJ9zaxacTfUt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(grams, raw_data):\n",
        "    chars = sorted(list(set(raw_data)))\n",
        "    mapping = dict((c, i) for i, c in enumerate(chars))\n",
        "\n",
        "    sequences = list()\n",
        "    for line in tqdm(grams, desc='Encoding'):\n",
        "        # integer encode line\n",
        "        encoded_seq = [mapping[char] for char in line]\n",
        "        # store\n",
        "        sequences.append(encoded_seq)\n",
        "    return sequences, mapping"
      ],
      "metadata": {
        "id": "D8tM7FaAgoAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encode()"
      ],
      "metadata": {
        "id": "AnaqXhqAgplY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Encoder model definition"
      ],
      "metadata": {
        "id": "-mO75Uvqf1M_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab, 20, input_length=2, trainable=True))\n",
        "model.add(GRU(25, recurrent_dropout=0.1, dropout=0.1))\n",
        "model.add(Dense(vocab, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=5)\n",
        "model.fit(x_tr, y_tr, epochs=10, verbose=1, validation_data=(x_val, y_val), callbacks=stop_early, batch_size=250)\n"
      ],
      "metadata": {
        "id": "dixehIytTlte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SOha87JCeMpF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}